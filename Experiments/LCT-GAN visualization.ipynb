{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xw4Yf479Tjgg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "from torchaudio.transforms import Spectrogram, InverseSpectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "px-sAGb4UH2F"
   },
   "outputs": [],
   "source": [
    "dir = \"D:/Projects/LCT-GAN/.data\"\n",
    "\n",
    "model = torch.jit.load(f'{dir}/FTFNet_scripted.pt')\n",
    "model.eval()\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 891,
     "status": "ok",
     "timestamp": 1764643518194,
     "user": {
      "displayName": "Charles Shang",
      "userId": "01716513894139651082"
     },
     "user_tz": 300
    },
    "id": "jvSkyTLb8rKI",
    "outputId": "19964aee-3a23-46b9-db1a-04fd3ca03f8a"
   },
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=TorchWrapper\n",
       "  (model): RecursiveScriptModule(\n",
       "    original_name=FTFNet\n",
       "    (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (conv3): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (deconv2): RecursiveScriptModule(original_name=ConvTranspose2d)\n",
       "    (deconv3): RecursiveScriptModule(original_name=ConvTranspose2d)\n",
       "    (deconv4): RecursiveScriptModule(original_name=ConvTranspose2d)\n",
       "    (activation): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "    (activations): RecursiveScriptModule(original_name=Sigmoid)\n",
       "    (skip2): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (skip3): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (skip4): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (GRUf1): RecursiveScriptModule(\n",
       "      original_name=GRUblockf\n",
       "      (gru1): RecursiveScriptModule(original_name=GRU)\n",
       "      (gru2): RecursiveScriptModule(original_name=GRU)\n",
       "      (gru3): RecursiveScriptModule(original_name=GRU)\n",
       "      (gru4): RecursiveScriptModule(original_name=GRU)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=MultiheadAttention\n",
       "        (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "      )\n",
       "      (activationtrans): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "      (layernorm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (layernorm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (lin): RecursiveScriptModule(original_name=Linear)\n",
       "    )\n",
       "    (GRUf2): RecursiveScriptModule(\n",
       "      original_name=GRUblockf\n",
       "      (gru1): RecursiveScriptModule(original_name=GRU)\n",
       "      (gru2): RecursiveScriptModule(original_name=GRU)\n",
       "      (gru3): RecursiveScriptModule(original_name=GRU)\n",
       "      (gru4): RecursiveScriptModule(original_name=GRU)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=MultiheadAttention\n",
       "        (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "      )\n",
       "      (activationtrans): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "      (layernorm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (layernorm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (lin): RecursiveScriptModule(original_name=Linear)\n",
       "    )\n",
       "    (GRUt1): RecursiveScriptModule(\n",
       "      original_name=GRUblockt\n",
       "      (gru1): RecursiveScriptModule(original_name=GRU)\n",
       "      (gru2): RecursiveScriptModule(original_name=GRU)\n",
       "      (gru3): RecursiveScriptModule(original_name=GRU)\n",
       "      (gru4): RecursiveScriptModule(original_name=GRU)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=MultiheadAttention\n",
       "        (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "      )\n",
       "      (activationtrans): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "      (layernorm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (layernorm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (lin): RecursiveScriptModule(original_name=Linear)\n",
       "    )\n",
       "    (layernorm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "    (pad): RecursiveScriptModule(original_name=ConstantPad2d)\n",
       "    (act_final): RecursiveScriptModule(original_name=ReLU)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    inputs: Tensor) -> Tensor:\n",
      "  inputs0 = torch.unsqueeze(inputs, 0)\n",
      "  inputs_mag = torch.pow(torch.abs(inputs0), 0.29999999999999999)\n",
      "  model = self.model\n",
      "  mask_preds = (model).forward(inputs_mag, )\n",
      "  outputs = torch.mul(inputs_mag, mask_preds)\n",
      "  outputs0 = torch.pow(outputs, 3.3333333333333335)\n",
      "  _0 = torch.mul(torch.angle(inputs0), 0.+1.j)\n",
      "  outputs1 = torch.mul(outputs0, torch.exp(_0))\n",
      "  _1 = torch.squeeze(torch.permute(outputs1, [0, 1, 3, 2]))\n",
      "  return _1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.___torch_mangle_11.TorchWrapper,\n",
       "      %inputs.1 : Tensor):\n",
       "  %47 : complex = prim::Constant[value=0.+1.j]()\n",
       "  %3 : int = prim::Constant[value=0]() # /tmp/ipykernel_1855/2753369034.py:21:34\n",
       "  %7 : float = prim::Constant[value=0.29999999999999999]() # /tmp/ipykernel_1855/2753369034.py:22:50\n",
       "  %18 : float = prim::Constant[value=3.3333333333333335]() # :0:0\n",
       "  %31 : int = prim::Constant[value=1]() # /tmp/ipykernel_1855/2753369034.py:27:37\n",
       "  %32 : int = prim::Constant[value=3]() # /tmp/ipykernel_1855/2753369034.py:27:40\n",
       "  %33 : int = prim::Constant[value=2]() # /tmp/ipykernel_1855/2753369034.py:27:43\n",
       "  %inputs0.1 : Tensor = aten::unsqueeze(%inputs.1, %3) # /tmp/ipykernel_1855/2753369034.py:21:17\n",
       "  %6 : Tensor = aten::abs(%inputs0.1) # /tmp/ipykernel_1855/2753369034.py:22:31\n",
       "  %inputs_mag.1 : Tensor = aten::pow(%6, %7) # /tmp/ipykernel_1855/2753369034.py:22:21\n",
       "  %model.1 : __torch__.lct_la1n.FTFNet = prim::GetAttr[name=\"model\"](%self.1)\n",
       "  %mask_preds.1 : Tensor = prim::CallMethod[name=\"forward\"](%model.1, %inputs_mag.1) # /tmp/ipykernel_1855/2753369034.py:23:21\n",
       "  %outputs.1 : Tensor = aten::mul(%inputs_mag.1, %mask_preds.1) # /tmp/ipykernel_1855/2753369034.py:24:18\n",
       "  %outputs0.1 : Tensor = aten::pow(%outputs.1, %18) # /tmp/ipykernel_1855/2753369034.py:25:18\n",
       "  %21 : Tensor = aten::angle(%inputs0.1) # /tmp/ipykernel_1855/2753369034.py:26:43\n",
       "  %25 : Tensor = aten::mul(%21, %47) # <string>:3:9\n",
       "  %28 : Tensor = aten::exp(%25) # /tmp/ipykernel_1855/2753369034.py:26:28\n",
       "  %outputs1.1 : Tensor = aten::mul(%outputs0.1, %28) # /tmp/ipykernel_1855/2753369034.py:26:18\n",
       "  %34 : int[] = prim::ListConstruct(%3, %31, %32, %33)\n",
       "  %35 : Tensor = aten::permute(%outputs1.1, %34) # /tmp/ipykernel_1855/2753369034.py:27:18\n",
       "  %37 : Tensor = aten::squeeze(%35) # /tmp/ipykernel_1855/2753369034.py:27:18\n",
       "  return (%37)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " : RecursiveScriptModule\n",
      "model : RecursiveScriptModule\n",
      "model.conv1 : RecursiveScriptModule\n",
      "model.conv2 : RecursiveScriptModule\n",
      "model.conv3 : RecursiveScriptModule\n",
      "model.deconv2 : RecursiveScriptModule\n",
      "model.deconv3 : RecursiveScriptModule\n",
      "model.deconv4 : RecursiveScriptModule\n",
      "model.activation : RecursiveScriptModule\n",
      "model.activations : RecursiveScriptModule\n",
      "model.skip2 : RecursiveScriptModule\n",
      "model.skip3 : RecursiveScriptModule\n",
      "model.skip4 : RecursiveScriptModule\n",
      "model.GRUf1 : RecursiveScriptModule\n",
      "model.GRUf1.gru1 : RecursiveScriptModule\n",
      "model.GRUf1.gru2 : RecursiveScriptModule\n",
      "model.GRUf1.gru3 : RecursiveScriptModule\n",
      "model.GRUf1.gru4 : RecursiveScriptModule\n",
      "model.GRUf1.attn : RecursiveScriptModule\n",
      "model.GRUf1.attn.out_proj : RecursiveScriptModule\n",
      "model.GRUf1.activationtrans : RecursiveScriptModule\n",
      "model.GRUf1.layernorm1 : RecursiveScriptModule\n",
      "model.GRUf1.layernorm2 : RecursiveScriptModule\n",
      "model.GRUf1.lin : RecursiveScriptModule\n",
      "model.GRUf2 : RecursiveScriptModule\n",
      "model.GRUf2.gru1 : RecursiveScriptModule\n",
      "model.GRUf2.gru2 : RecursiveScriptModule\n",
      "model.GRUf2.gru3 : RecursiveScriptModule\n",
      "model.GRUf2.gru4 : RecursiveScriptModule\n",
      "model.GRUf2.attn : RecursiveScriptModule\n",
      "model.GRUf2.attn.out_proj : RecursiveScriptModule\n",
      "model.GRUf2.activationtrans : RecursiveScriptModule\n",
      "model.GRUf2.layernorm1 : RecursiveScriptModule\n",
      "model.GRUf2.layernorm2 : RecursiveScriptModule\n",
      "model.GRUf2.lin : RecursiveScriptModule\n",
      "model.GRUt1 : RecursiveScriptModule\n",
      "model.GRUt1.gru1 : RecursiveScriptModule\n",
      "model.GRUt1.gru2 : RecursiveScriptModule\n",
      "model.GRUt1.gru3 : RecursiveScriptModule\n",
      "model.GRUt1.gru4 : RecursiveScriptModule\n",
      "model.GRUt1.attn : RecursiveScriptModule\n",
      "model.GRUt1.attn.out_proj : RecursiveScriptModule\n",
      "model.GRUt1.activationtrans : RecursiveScriptModule\n",
      "model.GRUt1.layernorm1 : RecursiveScriptModule\n",
      "model.GRUt1.layernorm2 : RecursiveScriptModule\n",
      "model.GRUt1.lin : RecursiveScriptModule\n",
      "model.layernorm : RecursiveScriptModule\n",
      "model.pad : RecursiveScriptModule\n",
      "model.act_final : RecursiveScriptModule\n"
     ]
    }
   ],
   "source": [
    "for name, m in model.named_modules():\n",
    "    print(name, \":\", m.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.conv1.weight torch.Size([16, 1, 2, 3])\n",
      "model.conv1.bias torch.Size([16])\n",
      "model.conv2.weight torch.Size([32, 16, 2, 3])\n",
      "model.conv2.bias torch.Size([32])\n",
      "model.conv3.weight torch.Size([64, 32, 2, 3])\n",
      "model.conv3.bias torch.Size([64])\n",
      "model.deconv2.weight torch.Size([64, 32, 2, 3])\n",
      "model.deconv2.bias torch.Size([32])\n",
      "model.deconv3.weight torch.Size([32, 16, 2, 3])\n",
      "model.deconv3.bias torch.Size([16])\n",
      "model.deconv4.weight torch.Size([16, 1, 2, 3])\n",
      "model.deconv4.bias torch.Size([1])\n",
      "model.skip2.weight torch.Size([64, 1, 1, 1])\n",
      "model.skip2.bias torch.Size([64])\n",
      "model.skip3.weight torch.Size([32, 1, 1, 1])\n",
      "model.skip3.bias torch.Size([32])\n",
      "model.skip4.weight torch.Size([16, 1, 1, 1])\n",
      "model.skip4.bias torch.Size([16])\n",
      "model.GRUf1.gru1.weight_ih_l0 torch.Size([48, 16])\n",
      "model.GRUf1.gru1.weight_hh_l0 torch.Size([48, 16])\n",
      "model.GRUf1.gru1.bias_ih_l0 torch.Size([48])\n",
      "model.GRUf1.gru1.bias_hh_l0 torch.Size([48])\n",
      "model.GRUf1.gru1.weight_ih_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf1.gru1.weight_hh_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf1.gru1.bias_ih_l0_reverse torch.Size([48])\n",
      "model.GRUf1.gru1.bias_hh_l0_reverse torch.Size([48])\n",
      "model.GRUf1.gru2.weight_ih_l0 torch.Size([48, 16])\n",
      "model.GRUf1.gru2.weight_hh_l0 torch.Size([48, 16])\n",
      "model.GRUf1.gru2.bias_ih_l0 torch.Size([48])\n",
      "model.GRUf1.gru2.bias_hh_l0 torch.Size([48])\n",
      "model.GRUf1.gru2.weight_ih_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf1.gru2.weight_hh_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf1.gru2.bias_ih_l0_reverse torch.Size([48])\n",
      "model.GRUf1.gru2.bias_hh_l0_reverse torch.Size([48])\n",
      "model.GRUf1.gru3.weight_ih_l0 torch.Size([48, 16])\n",
      "model.GRUf1.gru3.weight_hh_l0 torch.Size([48, 16])\n",
      "model.GRUf1.gru3.bias_ih_l0 torch.Size([48])\n",
      "model.GRUf1.gru3.bias_hh_l0 torch.Size([48])\n",
      "model.GRUf1.gru3.weight_ih_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf1.gru3.weight_hh_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf1.gru3.bias_ih_l0_reverse torch.Size([48])\n",
      "model.GRUf1.gru3.bias_hh_l0_reverse torch.Size([48])\n",
      "model.GRUf1.gru4.weight_ih_l0 torch.Size([48, 16])\n",
      "model.GRUf1.gru4.weight_hh_l0 torch.Size([48, 16])\n",
      "model.GRUf1.gru4.bias_ih_l0 torch.Size([48])\n",
      "model.GRUf1.gru4.bias_hh_l0 torch.Size([48])\n",
      "model.GRUf1.gru4.weight_ih_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf1.gru4.weight_hh_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf1.gru4.bias_ih_l0_reverse torch.Size([48])\n",
      "model.GRUf1.gru4.bias_hh_l0_reverse torch.Size([48])\n",
      "model.GRUf1.attn.in_proj_weight torch.Size([192, 64])\n",
      "model.GRUf1.attn.in_proj_bias torch.Size([192])\n",
      "model.GRUf1.attn.out_proj.weight torch.Size([64, 64])\n",
      "model.GRUf1.attn.out_proj.bias torch.Size([64])\n",
      "model.GRUf1.layernorm1.weight torch.Size([64])\n",
      "model.GRUf1.layernorm1.bias torch.Size([64])\n",
      "model.GRUf1.layernorm2.weight torch.Size([64])\n",
      "model.GRUf1.layernorm2.bias torch.Size([64])\n",
      "model.GRUf1.lin.weight torch.Size([64, 128])\n",
      "model.GRUf1.lin.bias torch.Size([64])\n",
      "model.GRUf2.gru1.weight_ih_l0 torch.Size([48, 16])\n",
      "model.GRUf2.gru1.weight_hh_l0 torch.Size([48, 16])\n",
      "model.GRUf2.gru1.bias_ih_l0 torch.Size([48])\n",
      "model.GRUf2.gru1.bias_hh_l0 torch.Size([48])\n",
      "model.GRUf2.gru1.weight_ih_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf2.gru1.weight_hh_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf2.gru1.bias_ih_l0_reverse torch.Size([48])\n",
      "model.GRUf2.gru1.bias_hh_l0_reverse torch.Size([48])\n",
      "model.GRUf2.gru2.weight_ih_l0 torch.Size([48, 16])\n",
      "model.GRUf2.gru2.weight_hh_l0 torch.Size([48, 16])\n",
      "model.GRUf2.gru2.bias_ih_l0 torch.Size([48])\n",
      "model.GRUf2.gru2.bias_hh_l0 torch.Size([48])\n",
      "model.GRUf2.gru2.weight_ih_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf2.gru2.weight_hh_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf2.gru2.bias_ih_l0_reverse torch.Size([48])\n",
      "model.GRUf2.gru2.bias_hh_l0_reverse torch.Size([48])\n",
      "model.GRUf2.gru3.weight_ih_l0 torch.Size([48, 16])\n",
      "model.GRUf2.gru3.weight_hh_l0 torch.Size([48, 16])\n",
      "model.GRUf2.gru3.bias_ih_l0 torch.Size([48])\n",
      "model.GRUf2.gru3.bias_hh_l0 torch.Size([48])\n",
      "model.GRUf2.gru3.weight_ih_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf2.gru3.weight_hh_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf2.gru3.bias_ih_l0_reverse torch.Size([48])\n",
      "model.GRUf2.gru3.bias_hh_l0_reverse torch.Size([48])\n",
      "model.GRUf2.gru4.weight_ih_l0 torch.Size([48, 16])\n",
      "model.GRUf2.gru4.weight_hh_l0 torch.Size([48, 16])\n",
      "model.GRUf2.gru4.bias_ih_l0 torch.Size([48])\n",
      "model.GRUf2.gru4.bias_hh_l0 torch.Size([48])\n",
      "model.GRUf2.gru4.weight_ih_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf2.gru4.weight_hh_l0_reverse torch.Size([48, 16])\n",
      "model.GRUf2.gru4.bias_ih_l0_reverse torch.Size([48])\n",
      "model.GRUf2.gru4.bias_hh_l0_reverse torch.Size([48])\n",
      "model.GRUf2.attn.in_proj_weight torch.Size([192, 64])\n",
      "model.GRUf2.attn.in_proj_bias torch.Size([192])\n",
      "model.GRUf2.attn.out_proj.weight torch.Size([64, 64])\n",
      "model.GRUf2.attn.out_proj.bias torch.Size([64])\n",
      "model.GRUf2.layernorm1.weight torch.Size([64])\n",
      "model.GRUf2.layernorm1.bias torch.Size([64])\n",
      "model.GRUf2.layernorm2.weight torch.Size([64])\n",
      "model.GRUf2.layernorm2.bias torch.Size([64])\n",
      "model.GRUf2.lin.weight torch.Size([64, 128])\n",
      "model.GRUf2.lin.bias torch.Size([64])\n",
      "model.GRUt1.gru1.weight_ih_l0 torch.Size([48, 16])\n",
      "model.GRUt1.gru1.weight_hh_l0 torch.Size([48, 16])\n",
      "model.GRUt1.gru1.bias_ih_l0 torch.Size([48])\n",
      "model.GRUt1.gru1.bias_hh_l0 torch.Size([48])\n",
      "model.GRUt1.gru2.weight_ih_l0 torch.Size([48, 16])\n",
      "model.GRUt1.gru2.weight_hh_l0 torch.Size([48, 16])\n",
      "model.GRUt1.gru2.bias_ih_l0 torch.Size([48])\n",
      "model.GRUt1.gru2.bias_hh_l0 torch.Size([48])\n",
      "model.GRUt1.gru3.weight_ih_l0 torch.Size([48, 16])\n",
      "model.GRUt1.gru3.weight_hh_l0 torch.Size([48, 16])\n",
      "model.GRUt1.gru3.bias_ih_l0 torch.Size([48])\n",
      "model.GRUt1.gru3.bias_hh_l0 torch.Size([48])\n",
      "model.GRUt1.gru4.weight_ih_l0 torch.Size([48, 16])\n",
      "model.GRUt1.gru4.weight_hh_l0 torch.Size([48, 16])\n",
      "model.GRUt1.gru4.bias_ih_l0 torch.Size([48])\n",
      "model.GRUt1.gru4.bias_hh_l0 torch.Size([48])\n",
      "model.GRUt1.attn.in_proj_weight torch.Size([192, 64])\n",
      "model.GRUt1.attn.in_proj_bias torch.Size([192])\n",
      "model.GRUt1.attn.out_proj.weight torch.Size([64, 64])\n",
      "model.GRUt1.attn.out_proj.bias torch.Size([64])\n",
      "model.GRUt1.layernorm1.weight torch.Size([64])\n",
      "model.GRUt1.layernorm1.bias torch.Size([64])\n",
      "model.GRUt1.layernorm2.weight torch.Size([64])\n",
      "model.GRUt1.layernorm2.bias torch.Size([64])\n",
      "model.GRUt1.lin.weight torch.Size([64, 64])\n",
      "model.GRUt1.lin.bias torch.Size([64])\n",
      "model.layernorm.weight torch.Size([64])\n",
      "model.layernorm.bias torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.state_dict().items():\n",
    "    print(name, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'D:/Projects/LCT-GAN/.data/noisy_4.wav'\n",
    "framelen = 512\n",
    "hoplen = 256\n",
    "win = lambda x: torch.sqrt(torch.hann_window(x)).to(device) # sqrt-hann window\n",
    "to_spec = Spectrogram(n_fft=framelen, hop_length=hoplen, power=None, window_fn=win)\n",
    "from_spec = InverseSpectrogram(n_fft=framelen, hop_length=hoplen, window_fn=win)\n",
    "\n",
    "x, _ = librosa.load(audio_file, sr=16000)\n",
    "x = torch.tensor(x.astype(np.float32)).to(device).unsqueeze(0)\n",
    "inputs = to_spec(x).permute(0,2,1).cfloat() # from waveform to spectrogram (channel, T, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "model.eval()\n",
    "\n",
    "output = model(inputs)\n",
    "\n",
    "if isinstance(output, (list, tuple)):\n",
    "    output = output[0]\n",
    "\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "dot.format = \"png\"\n",
    "dot.render(\"ftfnet_graph\")\n",
    "\n",
    "print(\"Saved computation graph as ftfnet_graph.png\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPSRZnitTIrQyM2a9ntFb6d",
   "mount_file_id": "1bnhEIqq1kOssahaik_qKZrzc2tR6wM4Z",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
