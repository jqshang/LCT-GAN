{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xw4Yf479Tjgg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\LCT-GAN\\.venv\\Lib\\site-packages\\df\\io.py:9: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.\n",
      "  from torchaudio.backend.common import AudioMetaData\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from df.enhance import init_df\n",
    "\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "cwd = Path(os.getcwd()).resolve()\n",
    "repo_root = cwd if (cwd / \"metrics.py\").exists() else cwd.parent\n",
    "sys.path.insert(0, str(repo_root))\n",
    "from util import ModelComparator\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().resolve().parent))\n",
    "from models.generator import LCTGenerator, LCTGeneratorConfig\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "px-sAGb4UH2F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-22 21:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on torch 2.8.0+cpu\u001b[0m\n",
      "\u001b[32m2025-12-22 21:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on host hashbrownmsi\u001b[0m\n",
      "\u001b[32m2025-12-22 21:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mGit commit: ff666f6, branch: main\u001b[0m\n",
      "\u001b[32m2025-12-22 21:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-12-22 21:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mUsing DeepFilterNet3 model at C:\\Users\\12624\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-12-22 21:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-12-22 21:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint C:\\Users\\12624\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\\checkpoints\\model_120.ckpt.best with epoch 120\u001b[0m\n",
      "\u001b[32m2025-12-22 21:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cpu\u001b[0m\n",
      "\u001b[32m2025-12-22 21:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jit = torch.jit.load(\"D:/Projects/LCT-GAN/.data/FTFNet_scripted.pt\", map_location=device).eval()\n",
    "\n",
    "ftf_model = jit.model if hasattr(jit, \"model\") else jit\n",
    "ftf_sd = ftf_model.state_dict()\n",
    "\n",
    "my_model = LCTGenerator(LCTGeneratorConfig()).to(device).eval()\n",
    "my_model.load_state_dict(ftf_sd, strict=True)\n",
    "\n",
    "\n",
    "df_model, df_state, _ = init_df()\n",
    "df_sr = df_state.sr()\n",
    "\n",
    "mc = ModelComparator(lct = jit, my_lct=my_model, dfn=df_model, dfn_state=df_state, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5xiDeTqoXKXG"
   },
   "outputs": [],
   "source": [
    "audio_files = {\n",
    "    \"impulse\": {\n",
    "        \"clean\": \"D:/Projects/LCT-GAN/.data/subjective_test_audios/impulse/clean_fileid_1.wav\",\n",
    "        \"noisy\": \"D:/Projects/LCT-GAN/.data/subjective_test_audios/impulse/noisy_fileid_1_snr14.25_tl-23.wav\",\n",
    "    },\n",
    "    \"music\": {\n",
    "        \"clean\": \"D:/Projects/LCT-GAN/.data/subjective_test_audios/music/clean_fileid_4.wav\",\n",
    "        \"noisy\": \"D:/Projects/LCT-GAN/.data/subjective_test_audios/music/noisy_fileid_4_snr14.07_tl-24.wav\",\n",
    "    },\n",
    "    \"roadside\": {\n",
    "        \"clean\": None,\n",
    "        \"noisy\": \"D:/Projects/LCT-GAN/.data/subjective_test_audios/roadside/noisy_fileid_0.wav\",\n",
    "    },\n",
    "    \"static1\": {\n",
    "        \"clean\": \"D:/Projects/LCT-GAN/.data/subjective_test_audios/static1/clean_fileid_0.wav\",\n",
    "        \"noisy\": \"D:/Projects/LCT-GAN/.data/subjective_test_audios/static1/noisy_fileid_0_snr-3.34_tl-17.wav\",\n",
    "    },\n",
    "    \"static2\": {\n",
    "        \"clean\": \"D:/Projects/LCT-GAN/.data/subjective_test_audios/static2/clean_fileid_1.wav\",\n",
    "        \"noisy\": \"D:/Projects/LCT-GAN/.data/subjective_test_audios/static2/noisy_fileid_1_snr14.25_tl-23.wav\",\n",
    "    },\n",
    "    \"water\": {\n",
    "        \"clean\": \"D:/Projects/LCT-GAN/.data/subjective_test_audios/water/clean_fileid_2.wav\",\n",
    "        \"noisy\": \"D:/Projects/LCT-GAN/.data/subjective_test_audios/water/noisy_fileid_2_snr-2.39_tl-30.wav\",\n",
    "    },\n",
    "}\n",
    "\n",
    "out_dir = \"D:/Projects/LCT-GAN/.data/enhanced_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing category: impulse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\LCT-GAN\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing category: music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\LCT-GAN\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing category: roadside\n",
      "Processing category: static1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\LCT-GAN\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing category: static2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\LCT-GAN\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing category: water\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\LCT-GAN\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for category, paths in audio_files.items():\n",
    "    print(f\"Processing category: {category}\")\n",
    "    results[category] = mc.process_one_file(\n",
    "        noisy_path=paths[\"noisy\"],\n",
    "        out_dir=f\"{out_dir}/{category}/\",\n",
    "        clean_path=paths[\"clean\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "MODELS = (\"ftfnet\", \"dfn\", \"my_ftfnet\")\n",
    "METRICS = (\"si_sdr\", \"pesq\", \"stoi\")\n",
    "\n",
    "\n",
    "def keep_category_model_metrics(\n",
    "    data,\n",
    "    *,\n",
    "    categories = None,   # e.g. {\"impulse\", \"music\"}; None = keep all\n",
    "    models = MODELS,\n",
    "    metrics = METRICS,\n",
    "    drop_models_with_no_metrics: bool = True,     # useful for \"roadside\"\n",
    "):\n",
    "    cat_set = set(categories) if categories is not None else None\n",
    "\n",
    "    out = {}\n",
    "    for category, cat_dict in data.items():\n",
    "        if cat_set is not None and category not in cat_set:\n",
    "            continue\n",
    "\n",
    "        kept_models = {}\n",
    "        for model in models:\n",
    "            if model not in cat_dict:\n",
    "                continue\n",
    "\n",
    "            model_dict = cat_dict[model] or {}\n",
    "            kept_metrics = {m: model_dict.get(m) for m in metrics}\n",
    "\n",
    "            if drop_models_with_no_metrics and all(v is None for v in kept_metrics.values()):\n",
    "                continue\n",
    "\n",
    "            kept_models[model] = kept_metrics\n",
    "\n",
    "        if kept_models:\n",
    "            out[category] = kept_models\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filtered = keep_category_model_metrics(results)\n",
    "\n",
    "rows = [\n",
    "    {\"category\": category, \"model\": model, **metrics}\n",
    "    for category, models_dict in filtered.items()\n",
    "    for model, metrics in models_dict.items()\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values([\"category\", \"model\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>model</th>\n",
       "      <th>si_sdr</th>\n",
       "      <th>pesq</th>\n",
       "      <th>stoi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>impulse</td>\n",
       "      <td>dfn</td>\n",
       "      <td>15.979971</td>\n",
       "      <td>2.830872</td>\n",
       "      <td>0.961708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>impulse</td>\n",
       "      <td>ftfnet</td>\n",
       "      <td>20.484844</td>\n",
       "      <td>3.407346</td>\n",
       "      <td>0.980956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>impulse</td>\n",
       "      <td>my_ftfnet</td>\n",
       "      <td>-9.131330</td>\n",
       "      <td>1.027396</td>\n",
       "      <td>0.602254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>music</td>\n",
       "      <td>dfn</td>\n",
       "      <td>20.817392</td>\n",
       "      <td>3.575815</td>\n",
       "      <td>0.851110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>music</td>\n",
       "      <td>ftfnet</td>\n",
       "      <td>18.288195</td>\n",
       "      <td>3.727750</td>\n",
       "      <td>0.866259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>music</td>\n",
       "      <td>my_ftfnet</td>\n",
       "      <td>-15.402922</td>\n",
       "      <td>1.091536</td>\n",
       "      <td>0.445325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>static1</td>\n",
       "      <td>dfn</td>\n",
       "      <td>7.943667</td>\n",
       "      <td>1.645568</td>\n",
       "      <td>0.903140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>static1</td>\n",
       "      <td>ftfnet</td>\n",
       "      <td>7.524585</td>\n",
       "      <td>1.805562</td>\n",
       "      <td>0.913023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>static1</td>\n",
       "      <td>my_ftfnet</td>\n",
       "      <td>-12.782477</td>\n",
       "      <td>1.051258</td>\n",
       "      <td>0.496695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>static2</td>\n",
       "      <td>dfn</td>\n",
       "      <td>15.979971</td>\n",
       "      <td>2.830872</td>\n",
       "      <td>0.961708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>static2</td>\n",
       "      <td>ftfnet</td>\n",
       "      <td>20.484844</td>\n",
       "      <td>3.407346</td>\n",
       "      <td>0.980956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>static2</td>\n",
       "      <td>my_ftfnet</td>\n",
       "      <td>-9.131330</td>\n",
       "      <td>1.027396</td>\n",
       "      <td>0.602254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>water</td>\n",
       "      <td>dfn</td>\n",
       "      <td>2.348073</td>\n",
       "      <td>1.919497</td>\n",
       "      <td>0.683483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>water</td>\n",
       "      <td>ftfnet</td>\n",
       "      <td>3.170262</td>\n",
       "      <td>1.381419</td>\n",
       "      <td>0.685414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>water</td>\n",
       "      <td>my_ftfnet</td>\n",
       "      <td>-15.268193</td>\n",
       "      <td>1.039189</td>\n",
       "      <td>0.528412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category      model     si_sdr      pesq      stoi\n",
       "0   impulse        dfn  15.979971  2.830872  0.961708\n",
       "1   impulse     ftfnet  20.484844  3.407346  0.980956\n",
       "2   impulse  my_ftfnet  -9.131330  1.027396  0.602254\n",
       "3     music        dfn  20.817392  3.575815  0.851110\n",
       "4     music     ftfnet  18.288195  3.727750  0.866259\n",
       "5     music  my_ftfnet -15.402922  1.091536  0.445325\n",
       "6   static1        dfn   7.943667  1.645568  0.903140\n",
       "7   static1     ftfnet   7.524585  1.805562  0.913023\n",
       "8   static1  my_ftfnet -12.782477  1.051258  0.496695\n",
       "9   static2        dfn  15.979971  2.830872  0.961708\n",
       "10  static2     ftfnet  20.484844  3.407346  0.980956\n",
       "11  static2  my_ftfnet  -9.131330  1.027396  0.602254\n",
       "12    water        dfn   2.348073  1.919497  0.683483\n",
       "13    water     ftfnet   3.170262  1.381419  0.685414\n",
       "14    water  my_ftfnet -15.268193  1.039189  0.528412"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试：\n",
    "# 1. 音频缩20/30db，inference\n",
    "# 2. 音频声音小，噪声大\n",
    "#    换两种噪声：water这个clean，换其他几个噪声进行测试\n",
    "# 3. 人声再小一点，测试不同噪声\n",
    "# 4. noisy信号再放大一点，做一点饱和，削顶\n",
    "#    95% （5%/2%/3% 数据饱和），削顶之后再降回去（一部分饱和）\n",
    "#    饱和能发现强大模型效果差别\n",
    "# 5. wind的噪声 和 开车的噪声\n",
    "\n",
    "\n",
    "# 训练一下，再去测试，voicebank 8/2 "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPSRZnitTIrQyM2a9ntFb6d",
   "mount_file_id": "1bnhEIqq1kOssahaik_qKZrzc2tR6wM4Z",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
